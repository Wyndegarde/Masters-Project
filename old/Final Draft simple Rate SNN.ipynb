{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages and Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import time\n",
    "from torchsummary import summary\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from PIL import Image, ImageFile\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, SubsetRandomSampler, WeightedRandomSampler\n",
    "from torchvision import datasets, transforms, utils\n",
    "import snntorch as snn\n",
    "from snntorch import surrogate\n",
    "from snntorch import spikegen\n",
    "import snntorch.spikeplot as splt\n",
    "import math\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "#print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#data_path='/data/mnist'\n",
    "data_path = '\\\\Users\\\\liamh\\\\OneDrive - University of Strathclyde\\\\University'\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Training Parameters\n",
    "batch_size=128\n",
    "\n",
    "# Network Architecture\n",
    "num_hidden = 350\n",
    "num_outputs = 10\n",
    "num_steps = 25\n",
    "\n",
    "# Convolutional layer parameters \n",
    "conv_kernel_size = 3\n",
    "conv_stride_length = 1 \n",
    "conv_padding_size = 1\n",
    "mp_kernel_size = 3 \n",
    "mp_stride_length = 2 \n",
    "mp_padding_size = 0\n",
    "\n",
    "# Temporal Dynamics\n",
    "time_step = 1e-3\n",
    "tau_mem = 2e-2\n",
    "beta = float(np.exp(-time_step/tau_mem))\n",
    "\n",
    "# Loss Function\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_in_data(res, ratio = 1):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((res, res)), #Resize images to 28*28\n",
    "        transforms.Grayscale(), # Make sure image is grayscale\n",
    "        transforms.ToTensor()]) # change each image array to a tensor which automatically scales inputs to [0,1]\n",
    "\n",
    "    mnist_train = datasets.MNIST(data_path, train=True, download=True, transform=transform) # Download training set and apply transformations. \n",
    "    mnist_test = datasets.MNIST(data_path, train=False, download=True, transform=transform) # same for test set\n",
    "\n",
    "    train_len = int(len(mnist_train)/ratio)\n",
    "    valid_len = len(mnist_train) - train_len\n",
    "    train_dataset, _ = random_split(mnist_train, (train_len, valid_len), generator=torch.Generator().manual_seed(42))\n",
    "    \n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True) # Load the data into the DataLoader so it's passed through the model, shuffled in batches. \n",
    "    valid_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    \n",
    "    return train_loader, valid_loader\n",
    "\n",
    "def output_formula(input_size, filter_size, padding, stride):\n",
    "    formula = math.floor(((((input_size - filter_size + 2*padding)/stride) + 1)))\n",
    "    \n",
    "    return formula \n",
    "\n",
    "def all_output_sizes(res, conv_filter = 3, conv_padding = 1, conv_stride = 1, mp_filter = 3, mp_padding = 0, mp_stride = 2):\n",
    "    \n",
    "    conv1 = output_formula(res, conv_filter, conv_padding, conv_stride)   # Output size from applying conv1 to input \n",
    "    mp1 = output_formula(conv1, mp_filter, mp_padding, mp_stride)         # Output size from applying max pooling 1 to conv1 \n",
    "    \n",
    "    conv2 = output_formula(mp1, conv_filter, conv_padding, conv_stride)   # Output size from applying conv2 to max pooling 1\n",
    "    conv3 = output_formula(conv2, conv_filter, conv_padding, conv_stride) # Output size from applying conv3 to conv 2\n",
    "    mp2 = output_formula(conv3, mp_filter, mp_padding, mp_stride)         # Output size from applying max pooling 2 to conv3\n",
    "    \n",
    "    conv4 = output_formula(mp2, conv_filter, conv_padding, conv_stride)   # Output size from applying conv 4 to max pooling 2\n",
    "    conv5 = output_formula(conv4, conv_filter, conv_padding, conv_stride) # Output size from applying conv5 to conv 4\n",
    "    mp3 = output_formula(conv5, mp_filter, mp_padding, mp_stride)         # Output size from applying max pooling 3 to conv 5\n",
    "    \n",
    "    outputs_I_need = [mp1, conv2, mp2, conv4, mp3]\n",
    "    \n",
    "    return outputs_I_need\n",
    "\n",
    "def plot_training_history(history, res, loss_upper = 1.05, acc_lower = -0.05, acc_higher = 105):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
    "    \n",
    "    \n",
    "    ax1.plot(history['avg_train_loss'], label='train loss',marker = 'o')\n",
    "    ax1.plot(history['avg_valid_loss'], label='validation loss',marker = 'o')\n",
    "\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax1.set_ylim([-0.05, loss_upper])\n",
    "    ax1.legend()\n",
    "    ax1.set_ylabel('Loss',fontsize = 16)\n",
    "    ax1.set_xlabel('Epoch',fontsize = 16)\n",
    "    \n",
    "    ax2.plot(history['train_accuracy'], label='train accuracy',marker = 'o')\n",
    "    ax2.plot(history['valid_accuracy'], label='validation accuracy',marker = 'o')\n",
    "\n",
    "    ax2.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2.set_ylim([acc_lower, acc_higher])\n",
    "\n",
    "    ax2.legend()\n",
    "\n",
    "    ax2.set_ylabel('Accuracy',fontsize = 16)\n",
    "    ax2.yaxis.set_major_formatter(PercentFormatter(100))\n",
    "    ax2.set_xlabel('Epoch',fontsize = 16)\n",
    "    fig.suptitle(f'Training history ({res}*{res})',fontsize = 20)\n",
    "    plt.show()\n",
    "\n",
    "def store_best_results(history):\n",
    "    # Want to take the last entry from each output(best results) and store them all in a Dataframe\n",
    "    placeholder = []\n",
    "    placeholder.append(history['avg_train_loss'][-1])\n",
    "    placeholder.append(history['train_accuracy'][-1])\n",
    "    placeholder.append(history['avg_valid_loss'][-1])\n",
    "    placeholder.append(history['valid_accuracy'][-1])\n",
    "    \n",
    "    return placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def put_results_in_df(output):\n",
    "    df = pd.DataFrame()\n",
    "    df['avg_train_loss'] = output['avg_train_loss']\n",
    "    df['train_accuracy'] = output['train_accuracy']\n",
    "    df['avg_valid_loss'] = output['avg_valid_loss']\n",
    "    df['valid_accuracy'] = output['valid_accuracy']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spiking CNN and training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Network\n",
    "class Rate_LIF_Snn_Net(nn.Module):\n",
    "    def __init__(self,res,spike_grad):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize layers\n",
    "        self.fc1 = nn.Linear(res*res, num_hidden)\n",
    "        self.lif1 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_hidden)\n",
    "        self.lif2 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
    "        self.fc3 = nn.Linear(num_hidden, num_outputs)\n",
    "        self.lif3 = snn.Leaky(beta=beta, spike_grad=spike_grad)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden states + output spike at t=0\n",
    "        spk1, mem1 = self.lif1.init_leaky(batch_size, num_hidden)\n",
    "        spk2, mem2 = self.lif2.init_leaky(batch_size, num_hidden)\n",
    "        spk3, mem3 = self.lif3.init_leaky(batch_size, num_outputs)\n",
    "\n",
    "        spk3_rec = []\n",
    "        mem3_rec = []\n",
    "\n",
    "        for step in range(num_steps):\n",
    "            cur1 = self.fc1(x[step])\n",
    "            spk1,  mem1 = self.lif1(cur1, mem1)\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "            cur3 = self.fc3(spk2)\n",
    "            spk3, mem3 = self.lif3(cur3, mem3)\n",
    "\n",
    "            spk3_rec.append(spk3)\n",
    "            mem3_rec.append(mem3)\n",
    "\n",
    "        return torch.stack(spk3_rec, dim=0), torch.stack(mem3_rec, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_rate_spiking_mse_model(resolution, train_loader, valid_loader, model, epochs ,device = device, verbose = True):\n",
    "    start_time = time.time()\n",
    "    print('Starting Training')\n",
    "    history = defaultdict(list)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, betas=(0.9, 0.999)) # Just an Adam Optimiser\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50], gamma=0.5)\n",
    "    \n",
    "    # Training variables\n",
    "    train_size = len(train_loader.dataset)\n",
    "    train_num_batches = len(train_loader)\n",
    "    \n",
    "    # validation variables\n",
    "    valid_size = len(valid_loader.dataset)\n",
    "    valid_num_batches = len(valid_loader)\n",
    "    \n",
    "    \n",
    "    for t in range(epochs):\n",
    "        \n",
    "        avg_train_loss = 0\n",
    "        correct = 0\n",
    "        avg_valid_loss, valid_correct = 0, 0\n",
    "        model.train()\n",
    "        for batch, (data_it, targets_it) in enumerate(train_loader):\n",
    "            data_it = data_it.to(device)\n",
    "            targets_it = targets_it.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Compute prediction and loss\n",
    "            spike_data = spikegen.rate(data_it, num_steps=num_steps, gain=1, offset=0)\n",
    "            spk_targets_it = torch.clamp(spikegen.to_one_hot(targets_it, 10) * 1.05, min=0.05)\n",
    "            \n",
    "            spk_rec, mem_rec = model(spike_data.view(num_steps,batch_size, -1)) \n",
    "            \n",
    "            # Sum loss over time steps: BPTT\n",
    "            loss = torch.zeros((1), dtype=dtype, device=device)   # creates a 1D tensor to store total loss over time. \n",
    "            for step in range(num_steps):\n",
    "                loss += loss_fn(mem_rec[step], spk_targets_it) # Loss at each time step is added to give total loss.\n",
    "\n",
    "            avg_train_loss += loss\n",
    "            \n",
    "            _, predicted = spk_rec.sum(dim=0).max(1) \n",
    "            correct += (predicted == targets_it).type(torch.float).sum().item()\n",
    "\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        avg_train_loss /= train_num_batches\n",
    "        accuracy = correct / train_size * 100      \n",
    "        history['avg_train_loss'].append(avg_train_loss.item())\n",
    "        history['train_accuracy'].append(accuracy)\n",
    "        \n",
    "        if verbose == True: \n",
    "            print(f\"Epoch {t+1} of {epochs}\")\n",
    "            print('-' * 15)\n",
    "            print(f\"Training Results, Epoch {t+1}:\\n Accuracy: {(accuracy):>0.1f}%, Avg loss: {avg_train_loss.item():>8f} \\n\")\n",
    "\n",
    "              ###################### VALIDATION LOOP ##############################\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for valid_data_it, valid_targets_it in valid_loader:\n",
    "                valid_data_it = valid_data_it.to(device)\n",
    "                valid_targets_it = valid_targets_it.to(device)\n",
    "                \n",
    "                valid_spike_data = spikegen.rate(valid_data_it, num_steps=num_steps, gain=1, offset=0)\n",
    "                valid_spk_targets_it = torch.clamp(spikegen.to_one_hot(targets_it, 10) * 1.05, min=0.05)\n",
    "\n",
    "                valid_spk_rec, valid_mem_rec = model(valid_spike_data.view(num_steps,batch_size, -1)) \n",
    "                \n",
    "                valid_loss = torch.zeros((1),dtype = dtype, device = device)    \n",
    "                for step in range(num_steps):\n",
    "                    valid_loss += loss_fn(valid_mem_rec[step], valid_spk_targets_it)\n",
    "                \n",
    "                avg_valid_loss += valid_loss\n",
    "                \n",
    "                \n",
    "                _, valid_predicted = valid_spk_rec.sum(dim=0).max(1)\n",
    "                valid_correct += (valid_predicted == valid_targets_it).type(torch.float).sum().item()\n",
    "        \n",
    "\n",
    "        avg_valid_loss /= valid_num_batches\n",
    "        valid_accuracy = valid_correct / valid_size * 100\n",
    "              \n",
    "        history['avg_valid_loss'].append(avg_valid_loss.item())\n",
    "        history['valid_accuracy'].append(valid_accuracy)\n",
    "        scheduler.step()\n",
    "        \n",
    "        if verbose == True: \n",
    "            print(f\"Validation Results, Epoch {t+1}: \\n Accuracy: {(valid_accuracy):>0.1f}%, Avg loss: {avg_valid_loss.item():>8f} \\n\")\n",
    "\n",
    "\n",
    "    print(\"Done!\")\n",
    "    print(f\"Final Train Accuracy: {(accuracy):>0.1f}%, and Avg loss: {avg_train_loss.item():>8f} \\n\")\n",
    "    print(f\"Final Validation Accuracy: {(valid_accuracy):>0.1f}%, and Avg loss: {avg_valid_loss.item():>8f} \\n\")\n",
    "    current_time = time.time()\n",
    "    total = current_time - start_time\n",
    "    print(f'Training time: {round(total/60,2)} minutes')\n",
    "    return history\n",
    "\n",
    "def get_rate_mse_snn_results(resolution,epochs = 20,ratio = 1, slope = 25, verbose = True):\n",
    "    spike_grad = surrogate.fast_sigmoid(slope = slope)\n",
    "    train, valid = load_in_data(resolution, ratio)\n",
    "    model = Rate_LIF_Snn_Net(resolution, spike_grad).to(device)\n",
    "\n",
    "    output = train_rate_spiking_mse_model(resolution, train,valid,model,epochs, verbose = verbose)\n",
    "    \n",
    "    return output\n",
    "\n",
    "#plot_training_history(output,resolution, ylimita = loss_upper, ylimitb_lower = acc_lower, ylimitb_upper = acc_higher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 56 * 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Done!\n",
      "Final Train Accuracy: 99.7%, and Avg loss: 0.378246 \n",
      "\n",
      "Final Validation Accuracy: 97.8%, and Avg loss: 4.397544 \n",
      "\n",
      "Training time: 28.07 minutes\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "output_56_r1 = get_rate_mse_snn_results(resolution = 56, ratio = 1, epochs = 75, slope = 5, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Done!\n",
      "Final Train Accuracy: 99.8%, and Avg loss: 0.391042 \n",
      "\n",
      "Final Validation Accuracy: 96.4%, and Avg loss: 4.384388 \n",
      "\n",
      "Training time: 8.94 minutes\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "output_56_r4 = get_rate_mse_snn_results(resolution = 56, ratio = 4, epochs = 75, slope = 5, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Done!\n",
      "Final Train Accuracy: 99.7%, and Avg loss: 0.381856 \n",
      "\n",
      "Final Validation Accuracy: 95.4%, and Avg loss: 4.401330 \n",
      "\n",
      "Training time: 13.82 minutes\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "output_56_r10 = get_rate_mse_snn_results(resolution = 56, ratio = 10, epochs = 75, slope = 5, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Done!\n",
      "Final Train Accuracy: 96.0%, and Avg loss: 0.564036 \n",
      "\n",
      "Final Validation Accuracy: 90.1%, and Avg loss: 4.349901 \n",
      "\n",
      "Training time: 7.18 minutes\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "output_56_r100 = get_rate_mse_snn_results(resolution = 56, ratio = 100, epochs = 75, slope = 5, verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 28 * 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Done!\n",
      "Final Train Accuracy: 99.8%, and Avg loss: 0.374357 \n",
      "\n",
      "Final Validation Accuracy: 98.1%, and Avg loss: 4.490624 \n",
      "\n",
      "Training time: 24.72 minutes\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "output_28_r1 = get_rate_mse_snn_results(resolution = 28, ratio = 1, epochs = 75, slope = 5, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Done!\n",
      "Final Train Accuracy: 99.8%, and Avg loss: 0.369790 \n",
      "\n",
      "Final Validation Accuracy: 97.2%, and Avg loss: 4.459857 \n",
      "\n",
      "Training time: 7.74 minutes\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "output_28_r4 = get_rate_mse_snn_results(resolution = 28, ratio = 4, epochs = 75, slope = 5, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Done!\n",
      "Final Train Accuracy: 99.7%, and Avg loss: 0.373571 \n",
      "\n",
      "Final Validation Accuracy: 96.0%, and Avg loss: 4.497210 \n",
      "\n",
      "Training time: 12.96 minutes\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "output_28_r10 = get_rate_mse_snn_results(resolution = 28, ratio = 10, epochs = 75, slope = 5, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Done!\n",
      "Final Train Accuracy: 96.0%, and Avg loss: 0.679214 \n",
      "\n",
      "Final Validation Accuracy: 90.4%, and Avg loss: 4.289697 \n",
      "\n",
      "Training time: 6.66 minutes\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "output_28_r100 = get_rate_mse_snn_results(resolution = 28, ratio = 100, epochs = 75, slope = 5, verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14 * 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Done!\n",
      "Final Train Accuracy: 99.6%, and Avg loss: 0.478637 \n",
      "\n",
      "Final Validation Accuracy: 98.2%, and Avg loss: 4.341120 \n",
      "\n",
      "Training time: 42.12 minutes\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "output_14_r1 = get_rate_mse_snn_results(resolution = 14, ratio = 1, epochs = 75, slope = 5, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Done!\n",
      "Final Train Accuracy: 99.4%, and Avg loss: 0.549297 \n",
      "\n",
      "Final Validation Accuracy: 97.3%, and Avg loss: 4.362268 \n",
      "\n",
      "Training time: 7.87 minutes\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "output_14_r4 = get_rate_mse_snn_results(resolution = 14, ratio = 4, epochs = 75, slope = 5, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Done!\n",
      "Final Train Accuracy: 99.6%, and Avg loss: 0.524845 \n",
      "\n",
      "Final Validation Accuracy: 96.5%, and Avg loss: 4.376784 \n",
      "\n",
      "Training time: 13.0 minutes\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "output_14_r10 = get_rate_mse_snn_results(resolution = 14, ratio = 10, epochs = 75, slope = 5, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Done!\n",
      "Final Train Accuracy: 96.0%, and Avg loss: 0.885986 \n",
      "\n",
      "Final Validation Accuracy: 92.0%, and Avg loss: 4.400379 \n",
      "\n",
      "Training time: 6.66 minutes\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "output_14_r100 = get_rate_mse_snn_results(resolution = 14, ratio = 100, epochs = 75, slope = 5, verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 * 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Done!\n",
      "Final Train Accuracy: 90.4%, and Avg loss: 1.024964 \n",
      "\n",
      "Final Validation Accuracy: 90.3%, and Avg loss: 4.011859 \n",
      "\n",
      "Training time: 24.72 minutes\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "output_7_r1 = get_rate_mse_snn_results(resolution = 7, ratio = 1, epochs = 75, slope = 5, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1296x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_training_history(output_7_r1,7, acc_lower = 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Done!\n",
      "Final Train Accuracy: 88.7%, and Avg loss: 1.164321 \n",
      "\n",
      "Final Validation Accuracy: 88.5%, and Avg loss: 4.067435 \n",
      "\n",
      "Training time: 7.74 minutes\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "output_7_r4 = get_rate_mse_snn_results(resolution = 7, ratio = 4, epochs = 75, slope = 5, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Done!\n",
      "Final Train Accuracy: 88.3%, and Avg loss: 1.188276 \n",
      "\n",
      "Final Validation Accuracy: 88.6%, and Avg loss: 4.088464 \n",
      "\n",
      "Training time: 12.74 minutes\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "output_7_r10 = get_rate_mse_snn_results(resolution = 7, ratio = 10, epochs = 75, slope = 5, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Done!\n",
      "Final Train Accuracy: 86.5%, and Avg loss: 1.513766 \n",
      "\n",
      "Final Validation Accuracy: 83.9%, and Avg loss: 4.155425 \n",
      "\n",
      "Training time: 6.47 minutes\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "output_7_r100 = get_rate_mse_snn_results(resolution = 7, ratio = 100, epochs = 75, slope = 5, verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_56_r1\n",
    "output_56_r4\n",
    "output_56_r10\n",
    "output_56_r100\n",
    "\n",
    "output_28_r1\n",
    "output_28_r4\n",
    "output_28_r10\n",
    "output_28_r100\n",
    "\n",
    "output_14_r1\n",
    "output_14_r4\n",
    "output_14_r10\n",
    "output_14_r100\n",
    "\n",
    "output_7_r1\n",
    "output_7_r4\n",
    "output_7_r10\n",
    "output_7_r100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_res = ['output_56', 'output_28', 'output_14','output_7']\n",
    "output_ratio = ['_r1','_r4','_r10','_r100']\n",
    "index = ['avg_train_loss', 'train_accuracy', 'avg_valid_loss', 'valid_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = []\n",
    "all_models = []\n",
    "for name in output_res:\n",
    "    for ratio in output_ratio: \n",
    "        model_name = name + ratio\n",
    "        all_models.append(model_name)\n",
    "        for indice in index: \n",
    "            column_name = name + ratio + '_' + indice\n",
    "            all_columns.append(column_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['avg_train_loss', 'train_accuracy', 'avg_valid_loss', 'valid_accuracy'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_56_r1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.13006120920181274,\n",
       " 0.042799513787031174,\n",
       " 0.03713303059339523,\n",
       " 0.06466007232666016,\n",
       " 0.015814419835805893,\n",
       " 0.03430761396884918,\n",
       " 0.0019204705022275448,\n",
       " 0.011888238601386547,\n",
       " 0.0019352637464180589,\n",
       " 0.008182739838957787,\n",
       " 0.017129648476839066,\n",
       " 0.02643691748380661,\n",
       " 0.0015373200876638293,\n",
       " 0.14406420290470123,\n",
       " 0.000397319789044559,\n",
       " 0.007249984424561262,\n",
       " 0.04614896699786186,\n",
       " 0.07822474092245102,\n",
       " 0.0012644941452890635,\n",
       " 0.0038358275778591633,\n",
       " 0.00786791555583477,\n",
       " 0.000664190505631268,\n",
       " 0.001168444869108498,\n",
       " 0.0002316593745490536,\n",
       " 0.005893235560506582,\n",
       " 0.0007707395707257092,\n",
       " 0.0001737207785481587,\n",
       " 3.402635411475785e-05,\n",
       " 3.451213342486881e-05,\n",
       " 5.471266194945201e-05,\n",
       " 0.0008975357632152736,\n",
       " 0.00015174300642684102,\n",
       " 0.0006222904194146395,\n",
       " 5.256674285192275e-06,\n",
       " 7.913309673313051e-06,\n",
       " 0.00016171134484466165,\n",
       " 0.000734230678062886,\n",
       " 1.4118486433289945e-05,\n",
       " 0.01709653064608574,\n",
       " 2.1993864720570855e-05,\n",
       " 1.7628976820560638e-06,\n",
       " 0.022050853818655014,\n",
       " 7.068630907269835e-07,\n",
       " 1.3781431334791705e-05,\n",
       " 0.0013350488152354956,\n",
       " 0.003219502279534936,\n",
       " 2.711762817853014e-06,\n",
       " 3.430059223319404e-05,\n",
       " 0.001625832635909319,\n",
       " 9.797412303669262e-07,\n",
       " 0.00045810462324880064,\n",
       " 4.594902748067398e-06,\n",
       " 1.704303684846309e-07,\n",
       " 9.631192369852215e-05,\n",
       " 7.178925898188027e-06,\n",
       " 4.1965745367633644e-06,\n",
       " 2.5238588818865537e-07,\n",
       " 8.284423529403284e-06,\n",
       " 8.11660211184062e-05,\n",
       " 0.0004598332161549479,\n",
       " 5.503922579919163e-07,\n",
       " 8.004375558812171e-06,\n",
       " 0.0005502012209035456,\n",
       " 4.824157144867058e-07,\n",
       " 1.9278174079317978e-07,\n",
       " 6.183738037179864e-07,\n",
       " 2.3841647589506465e-07,\n",
       " 0.0005763408844359219,\n",
       " 7.0311452873284e-06,\n",
       " 1.2944764193889569e-06,\n",
       " 1.667062292654009e-07,\n",
       " 1.3800985243506148e-06,\n",
       " 2.1669002308044583e-06,\n",
       " 2.235172047448941e-08,\n",
       " 8.381901395182467e-09]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locals()[all_models[0]]['avg_train_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for entry in all_models:\n",
    "    for key in index:\n",
    "        string = entry + '_' + key\n",
    "        \n",
    "        df[string] = locals()[entry][key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_56_r1_avg_train_loss</th>\n",
       "      <th>output_56_r1_train_accuracy</th>\n",
       "      <th>output_56_r1_avg_valid_loss</th>\n",
       "      <th>output_56_r1_valid_accuracy</th>\n",
       "      <th>output_56_r4_avg_train_loss</th>\n",
       "      <th>output_56_r4_train_accuracy</th>\n",
       "      <th>output_56_r4_avg_valid_loss</th>\n",
       "      <th>output_56_r4_valid_accuracy</th>\n",
       "      <th>output_56_r10_avg_train_loss</th>\n",
       "      <th>output_56_r10_train_accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>output_7_r4_avg_valid_loss</th>\n",
       "      <th>output_7_r4_valid_accuracy</th>\n",
       "      <th>output_7_r10_avg_train_loss</th>\n",
       "      <th>output_7_r10_train_accuracy</th>\n",
       "      <th>output_7_r10_avg_valid_loss</th>\n",
       "      <th>output_7_r10_valid_accuracy</th>\n",
       "      <th>output_7_r100_avg_train_loss</th>\n",
       "      <th>output_7_r100_train_accuracy</th>\n",
       "      <th>output_7_r100_avg_valid_loss</th>\n",
       "      <th>output_7_r100_valid_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.236469</td>\n",
       "      <td>87.881667</td>\n",
       "      <td>4.254372</td>\n",
       "      <td>94.92</td>\n",
       "      <td>1.824880</td>\n",
       "      <td>71.193333</td>\n",
       "      <td>4.293531</td>\n",
       "      <td>91.42</td>\n",
       "      <td>1.802772</td>\n",
       "      <td>70.233333</td>\n",
       "      <td>...</td>\n",
       "      <td>3.482444</td>\n",
       "      <td>59.48</td>\n",
       "      <td>2.231980</td>\n",
       "      <td>32.100000</td>\n",
       "      <td>3.329620</td>\n",
       "      <td>61.52</td>\n",
       "      <td>3.421453</td>\n",
       "      <td>9.166667</td>\n",
       "      <td>3.212257</td>\n",
       "      <td>9.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.861184</td>\n",
       "      <td>95.898333</td>\n",
       "      <td>4.317929</td>\n",
       "      <td>96.46</td>\n",
       "      <td>1.191878</td>\n",
       "      <td>92.733333</td>\n",
       "      <td>4.343641</td>\n",
       "      <td>93.24</td>\n",
       "      <td>1.196781</td>\n",
       "      <td>91.416667</td>\n",
       "      <td>...</td>\n",
       "      <td>3.676816</td>\n",
       "      <td>71.62</td>\n",
       "      <td>1.769224</td>\n",
       "      <td>67.550000</td>\n",
       "      <td>3.775719</td>\n",
       "      <td>75.03</td>\n",
       "      <td>2.648777</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.091301</td>\n",
       "      <td>11.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.762941</td>\n",
       "      <td>96.913333</td>\n",
       "      <td>4.350169</td>\n",
       "      <td>96.60</td>\n",
       "      <td>1.019259</td>\n",
       "      <td>94.740000</td>\n",
       "      <td>4.314682</td>\n",
       "      <td>94.32</td>\n",
       "      <td>1.017169</td>\n",
       "      <td>93.983333</td>\n",
       "      <td>...</td>\n",
       "      <td>3.823588</td>\n",
       "      <td>77.53</td>\n",
       "      <td>1.666852</td>\n",
       "      <td>74.333333</td>\n",
       "      <td>3.872702</td>\n",
       "      <td>77.68</td>\n",
       "      <td>2.347013</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>3.142592</td>\n",
       "      <td>19.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.706059</td>\n",
       "      <td>97.428333</td>\n",
       "      <td>4.361654</td>\n",
       "      <td>96.91</td>\n",
       "      <td>0.925328</td>\n",
       "      <td>95.773333</td>\n",
       "      <td>4.332899</td>\n",
       "      <td>95.09</td>\n",
       "      <td>0.916132</td>\n",
       "      <td>95.450000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.001494</td>\n",
       "      <td>81.86</td>\n",
       "      <td>1.629847</td>\n",
       "      <td>77.133333</td>\n",
       "      <td>3.937648</td>\n",
       "      <td>80.55</td>\n",
       "      <td>2.225049</td>\n",
       "      <td>21.166667</td>\n",
       "      <td>3.163729</td>\n",
       "      <td>27.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.661159</td>\n",
       "      <td>97.760000</td>\n",
       "      <td>4.410675</td>\n",
       "      <td>97.01</td>\n",
       "      <td>0.859063</td>\n",
       "      <td>96.560000</td>\n",
       "      <td>4.285552</td>\n",
       "      <td>95.52</td>\n",
       "      <td>0.860212</td>\n",
       "      <td>96.216667</td>\n",
       "      <td>...</td>\n",
       "      <td>4.038558</td>\n",
       "      <td>83.01</td>\n",
       "      <td>1.611562</td>\n",
       "      <td>80.450000</td>\n",
       "      <td>3.917810</td>\n",
       "      <td>81.81</td>\n",
       "      <td>2.166100</td>\n",
       "      <td>30.666667</td>\n",
       "      <td>3.207436</td>\n",
       "      <td>39.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.379313</td>\n",
       "      <td>99.713333</td>\n",
       "      <td>4.396052</td>\n",
       "      <td>97.78</td>\n",
       "      <td>0.381202</td>\n",
       "      <td>99.833333</td>\n",
       "      <td>4.384593</td>\n",
       "      <td>96.48</td>\n",
       "      <td>0.380402</td>\n",
       "      <td>99.733333</td>\n",
       "      <td>...</td>\n",
       "      <td>4.095155</td>\n",
       "      <td>88.70</td>\n",
       "      <td>1.208241</td>\n",
       "      <td>88.066667</td>\n",
       "      <td>4.110886</td>\n",
       "      <td>88.35</td>\n",
       "      <td>1.540018</td>\n",
       "      <td>83.833333</td>\n",
       "      <td>4.188341</td>\n",
       "      <td>83.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.378379</td>\n",
       "      <td>99.713333</td>\n",
       "      <td>4.374744</td>\n",
       "      <td>97.64</td>\n",
       "      <td>0.382697</td>\n",
       "      <td>99.833333</td>\n",
       "      <td>4.374391</td>\n",
       "      <td>96.56</td>\n",
       "      <td>0.379211</td>\n",
       "      <td>99.733333</td>\n",
       "      <td>...</td>\n",
       "      <td>4.090068</td>\n",
       "      <td>89.03</td>\n",
       "      <td>1.200703</td>\n",
       "      <td>88.166667</td>\n",
       "      <td>4.086699</td>\n",
       "      <td>88.02</td>\n",
       "      <td>1.503848</td>\n",
       "      <td>85.500000</td>\n",
       "      <td>4.206891</td>\n",
       "      <td>83.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.378047</td>\n",
       "      <td>99.710000</td>\n",
       "      <td>4.349506</td>\n",
       "      <td>97.74</td>\n",
       "      <td>0.382436</td>\n",
       "      <td>99.833333</td>\n",
       "      <td>4.389956</td>\n",
       "      <td>96.71</td>\n",
       "      <td>0.378228</td>\n",
       "      <td>99.733333</td>\n",
       "      <td>...</td>\n",
       "      <td>4.086252</td>\n",
       "      <td>88.50</td>\n",
       "      <td>1.185894</td>\n",
       "      <td>87.700000</td>\n",
       "      <td>4.137902</td>\n",
       "      <td>87.68</td>\n",
       "      <td>1.496451</td>\n",
       "      <td>85.166667</td>\n",
       "      <td>4.175988</td>\n",
       "      <td>83.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.378797</td>\n",
       "      <td>99.711667</td>\n",
       "      <td>4.354722</td>\n",
       "      <td>97.75</td>\n",
       "      <td>0.386458</td>\n",
       "      <td>99.833333</td>\n",
       "      <td>4.378465</td>\n",
       "      <td>96.44</td>\n",
       "      <td>0.381344</td>\n",
       "      <td>99.733333</td>\n",
       "      <td>...</td>\n",
       "      <td>4.070506</td>\n",
       "      <td>89.01</td>\n",
       "      <td>1.188205</td>\n",
       "      <td>88.066667</td>\n",
       "      <td>4.086351</td>\n",
       "      <td>88.21</td>\n",
       "      <td>1.509731</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>4.224326</td>\n",
       "      <td>84.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.378246</td>\n",
       "      <td>99.721667</td>\n",
       "      <td>4.397544</td>\n",
       "      <td>97.84</td>\n",
       "      <td>0.391042</td>\n",
       "      <td>99.833333</td>\n",
       "      <td>4.384388</td>\n",
       "      <td>96.41</td>\n",
       "      <td>0.381856</td>\n",
       "      <td>99.733333</td>\n",
       "      <td>...</td>\n",
       "      <td>4.067435</td>\n",
       "      <td>88.47</td>\n",
       "      <td>1.188276</td>\n",
       "      <td>88.283333</td>\n",
       "      <td>4.088464</td>\n",
       "      <td>88.61</td>\n",
       "      <td>1.513766</td>\n",
       "      <td>86.500000</td>\n",
       "      <td>4.155425</td>\n",
       "      <td>83.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows  64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    output_56_r1_avg_train_loss  output_56_r1_train_accuracy  \\\n",
       "0                      1.236469                    87.881667   \n",
       "1                      0.861184                    95.898333   \n",
       "2                      0.762941                    96.913333   \n",
       "3                      0.706059                    97.428333   \n",
       "4                      0.661159                    97.760000   \n",
       "..                          ...                          ...   \n",
       "70                     0.379313                    99.713333   \n",
       "71                     0.378379                    99.713333   \n",
       "72                     0.378047                    99.710000   \n",
       "73                     0.378797                    99.711667   \n",
       "74                     0.378246                    99.721667   \n",
       "\n",
       "    output_56_r1_avg_valid_loss  output_56_r1_valid_accuracy  \\\n",
       "0                      4.254372                        94.92   \n",
       "1                      4.317929                        96.46   \n",
       "2                      4.350169                        96.60   \n",
       "3                      4.361654                        96.91   \n",
       "4                      4.410675                        97.01   \n",
       "..                          ...                          ...   \n",
       "70                     4.396052                        97.78   \n",
       "71                     4.374744                        97.64   \n",
       "72                     4.349506                        97.74   \n",
       "73                     4.354722                        97.75   \n",
       "74                     4.397544                        97.84   \n",
       "\n",
       "    output_56_r4_avg_train_loss  output_56_r4_train_accuracy  \\\n",
       "0                      1.824880                    71.193333   \n",
       "1                      1.191878                    92.733333   \n",
       "2                      1.019259                    94.740000   \n",
       "3                      0.925328                    95.773333   \n",
       "4                      0.859063                    96.560000   \n",
       "..                          ...                          ...   \n",
       "70                     0.381202                    99.833333   \n",
       "71                     0.382697                    99.833333   \n",
       "72                     0.382436                    99.833333   \n",
       "73                     0.386458                    99.833333   \n",
       "74                     0.391042                    99.833333   \n",
       "\n",
       "    output_56_r4_avg_valid_loss  output_56_r4_valid_accuracy  \\\n",
       "0                      4.293531                        91.42   \n",
       "1                      4.343641                        93.24   \n",
       "2                      4.314682                        94.32   \n",
       "3                      4.332899                        95.09   \n",
       "4                      4.285552                        95.52   \n",
       "..                          ...                          ...   \n",
       "70                     4.384593                        96.48   \n",
       "71                     4.374391                        96.56   \n",
       "72                     4.389956                        96.71   \n",
       "73                     4.378465                        96.44   \n",
       "74                     4.384388                        96.41   \n",
       "\n",
       "    output_56_r10_avg_train_loss  output_56_r10_train_accuracy  ...  \\\n",
       "0                       1.802772                     70.233333  ...   \n",
       "1                       1.196781                     91.416667  ...   \n",
       "2                       1.017169                     93.983333  ...   \n",
       "3                       0.916132                     95.450000  ...   \n",
       "4                       0.860212                     96.216667  ...   \n",
       "..                           ...                           ...  ...   \n",
       "70                      0.380402                     99.733333  ...   \n",
       "71                      0.379211                     99.733333  ...   \n",
       "72                      0.378228                     99.733333  ...   \n",
       "73                      0.381344                     99.733333  ...   \n",
       "74                      0.381856                     99.733333  ...   \n",
       "\n",
       "    output_7_r4_avg_valid_loss  output_7_r4_valid_accuracy  \\\n",
       "0                     3.482444                       59.48   \n",
       "1                     3.676816                       71.62   \n",
       "2                     3.823588                       77.53   \n",
       "3                     4.001494                       81.86   \n",
       "4                     4.038558                       83.01   \n",
       "..                         ...                         ...   \n",
       "70                    4.095155                       88.70   \n",
       "71                    4.090068                       89.03   \n",
       "72                    4.086252                       88.50   \n",
       "73                    4.070506                       89.01   \n",
       "74                    4.067435                       88.47   \n",
       "\n",
       "    output_7_r10_avg_train_loss  output_7_r10_train_accuracy  \\\n",
       "0                      2.231980                    32.100000   \n",
       "1                      1.769224                    67.550000   \n",
       "2                      1.666852                    74.333333   \n",
       "3                      1.629847                    77.133333   \n",
       "4                      1.611562                    80.450000   \n",
       "..                          ...                          ...   \n",
       "70                     1.208241                    88.066667   \n",
       "71                     1.200703                    88.166667   \n",
       "72                     1.185894                    87.700000   \n",
       "73                     1.188205                    88.066667   \n",
       "74                     1.188276                    88.283333   \n",
       "\n",
       "    output_7_r10_avg_valid_loss  output_7_r10_valid_accuracy  \\\n",
       "0                      3.329620                        61.52   \n",
       "1                      3.775719                        75.03   \n",
       "2                      3.872702                        77.68   \n",
       "3                      3.937648                        80.55   \n",
       "4                      3.917810                        81.81   \n",
       "..                          ...                          ...   \n",
       "70                     4.110886                        88.35   \n",
       "71                     4.086699                        88.02   \n",
       "72                     4.137902                        87.68   \n",
       "73                     4.086351                        88.21   \n",
       "74                     4.088464                        88.61   \n",
       "\n",
       "    output_7_r100_avg_train_loss  output_7_r100_train_accuracy  \\\n",
       "0                       3.421453                      9.166667   \n",
       "1                       2.648777                     10.000000   \n",
       "2                       2.347013                     13.500000   \n",
       "3                       2.225049                     21.166667   \n",
       "4                       2.166100                     30.666667   \n",
       "..                           ...                           ...   \n",
       "70                      1.540018                     83.833333   \n",
       "71                      1.503848                     85.500000   \n",
       "72                      1.496451                     85.166667   \n",
       "73                      1.509731                     85.000000   \n",
       "74                      1.513766                     86.500000   \n",
       "\n",
       "    output_7_r100_avg_valid_loss  output_7_r100_valid_accuracy  \n",
       "0                       3.212257                          9.76  \n",
       "1                       3.091301                         11.05  \n",
       "2                       3.142592                         19.10  \n",
       "3                       3.163729                         27.91  \n",
       "4                       3.207436                         39.42  \n",
       "..                           ...                           ...  \n",
       "70                      4.188341                         83.76  \n",
       "71                      4.206891                         83.77  \n",
       "72                      4.175988                         83.88  \n",
       "73                      4.224326                         84.01  \n",
       "74                      4.155425                         83.94  \n",
       "\n",
       "[75 rows x 64 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('all_simple_rate_snn_training_histories.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Masters-Project-uJcOuMmr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "42dcfe4d3ff455891dcc0edcfbcf5ccac60cdc0dc8dd9e15fc951f2fbb26b4f0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
